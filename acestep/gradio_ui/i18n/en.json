{
  "app": {
    "title": "ğŸ›ï¸ ACE-Step V1.5 PlaygroundğŸ’¡",
    "subtitle": "Pushing the Boundaries of Open-Source Music Generation"
  },
  "common": {
    "required_legend": "* Required field"
  },
  "dataset": {
    "title": "ğŸ“Š Dataset Explorer",
    "dataset_label": "Dataset",
    "dataset_info": "Choose dataset to explore.",
    "import_btn": "ğŸ“¥ Import Dataset",
    "search_type_label": "Search Type",
    "search_type_info": "How to find items.",
    "search_value_label": "Search Value",
    "search_value_placeholder": "Enter keys or index (leave empty for random)",
    "search_value_info": "Keys: exact match, Index: 0 to dataset size-1.",
    "instruction_label": "ğŸ“ Instruction",
    "instruction_placeholder": "No instruction available",
    "metadata_title": "ğŸ“‹ Item Metadata (JSON)",
    "metadata_label": "Complete Item Information",
    "source_audio": "Source Audio",
    "target_audio": "Target Audio",
    "reference_audio": "Reference Audio",
    "get_item_btn": "ğŸ” Get Item",
    "use_src_checkbox": "Use Source Audio from Dataset",
    "use_src_info": "Check to use the source audio from dataset.",
    "data_status_label": "ğŸ“Š Data Status",
    "data_status_default": "âŒ No dataset imported",
    "autofill_btn": "ğŸ“‹ Auto-fill Generation Form"
  },
  "service": {
    "title": "ğŸ”§ Service Configuration",
    "checkpoint_label": "Checkpoint File",
    "checkpoint_info": "Select a trained model checkpoint file (full path or filename).",
    "refresh_btn": "ğŸ”„ Refresh",
    "model_path_label": "Main Model Path",
    "model_path_info": "Select the model configuration directory (auto-scanned from checkpoints).",
    "device_label": "Device",
    "device_info": "Processing device (auto-detect recommended).",
    "lm_model_path_label": "5Hz LM Model Path",
    "lm_model_path_info": "Select the 5Hz LM model checkpoint (auto-scanned from checkpoints).",
    "backend_label": "5Hz LM Backend",
    "backend_info": "Select backend for 5Hz LM: vllm (faster) or pt (PyTorch, more compatible).",
    "init_llm_label": "Initialize 5Hz LM",
    "init_llm_info": "Check to initialize 5Hz LM during service initialization.",
    "flash_attention_label": "Use Flash Attention",
    "flash_attention_info_enabled": "Enable flash attention for faster inference (requires flash_attn package).",
    "flash_attention_info_disabled": "Flash attention not available (flash_attn package not installed).",
    "offload_cpu_label": "Offload to CPU",
    "offload_cpu_info": "Offload models to CPU when not in use to save GPU memory.",
    "offload_dit_cpu_label": "Offload DiT to CPU",
    "offload_dit_cpu_info": "Offload DiT to CPU (needs Offload to CPU).",
    "compile_model_label": "Compile Model",
    "compile_model_info": "Use torch.compile to optimize model (required for quantization).",
    "quantization_label": "INT8 Quantization",
    "quantization_info": "Enable INT8 weight-only quantization to reduce VRAM usage (requires Compile Model).",
    "mlx_dit_label": "MLX DiT (Apple Silicon)",
    "mlx_dit_info_enabled": "Use native MLX for DiT diffusion on Apple Silicon (faster than MPS).",
    "mlx_dit_info_disabled": "MLX not available (requires macOS + Apple Silicon + mlx package).",
    "init_btn": "Initialize Service",
    "status_label": "Status",
    "language_label": "UI Language",
    "language_info": "Select interface language.",
    "gpu_auto_tier": "Auto-detected Tier",
    "tier_label": "GPU Tier Override",
    "tier_info": "Manually select GPU tier to adjust optimization defaults (offload, quantization, backend, etc.)."
  },
  "generation": {
    "tab_title": "ğŸµ Generation",
    "required_inputs": "ğŸ“ Required Inputs",
    "task_type_label": "Task Type *",
    "task_type_info": "Select the task type for generation.",
    "instruction_label": "Instruction",
    "instruction_info": "Instruction is automatically generated based on task type.",
    "load_btn": "ğŸ“‚ Load",
    "track_name_label": "Track Name",
    "track_name_info": "Select track name for lego/extract tasks.",
    "track_classes_label": "Track Names",
    "track_classes_info": "Select multiple track classes for complete task.",
    "audio_uploads": "ğŸµ Audio Uploads",
    "reference_audio": "Reference Audio",
    "source_audio": "Source Audio",
    "convert_codes_btn": "Convert to Codes",
    "analyze_btn": "ğŸ” Analyze",
    "sample_btn": "ğŸ² Click Me",
    "lm_codes_hints": "ğŸ¼ LM Codes Hints",
    "lm_codes_label": "LM Codes Hints",
    "lm_codes_placeholder": "<|audio_code_10695|><|audio_code_54246|>.",
    "lm_codes_info": "Paste LM codes hints for text2music generation.",
    "lm_codes_sample": "LM Codes Hints (Sample {n})",
    "lm_codes_sample_info": "Codes for sample {n}.",
    "transcribe_btn": "Transcribe",
    "repainting_controls": "ğŸ¨ Repainting Controls (seconds)",
    "repainting_start": "Repainting Start",
    "repainting_end": "Repainting End",
    "mode_label": "Generation Mode *",
    "mode_info": "Select a generation mode to get started.",
    "mode_info_simple": "Describe your music in natural language. AI will generate caption, lyrics and metadata for you.",
    "mode_info_custom": "Full control over caption, lyrics and all parameters.",
    "mode_info_remix": "Upload source audio to create a remix version with your caption and lyrics.",
    "mode_info_repaint": "Upload source audio and repaint a specific time range.",
    "mode_info_extract": "Extract a specific track (vocals, drums, etc.) from source audio.",
    "mode_info_lego": "Reassemble tracks: replace a specific track in the source audio.",
    "mode_info_complete": "Complete missing tracks in the source audio.",
    "mode_simple": "Simple",
    "mode_custom": "Custom",
    "simple_query_label": "Song Description *",
    "simple_query_placeholder": "Describe the music you want to create, e.g., 'a soft Bengali love song for a quiet evening'. Leave empty for a random sample.",
    "simple_query_info": "Enter a natural language description of the music you want to generate.",
    "simple_vocal_language_label": "Vocal Language",
    "simple_vocal_language_info": "Select preferred language(s) for lyrics. Use 'unknown' for any language.",
    "create_sample_btn": "Create Sample",
    "caption_title": "ğŸ“ Music Caption",
    "caption_label": "Music Caption",
    "caption_placeholder": "A peaceful acoustic guitar melody with soft vocals.",
    "caption_info": "Describe the style, genre, instruments, and mood.",
    "lyrics_title": "ğŸ“ Lyrics",
    "lyrics_label": "Lyrics",
    "lyrics_placeholder": "[Verse 1]\\nUnder the starry night\\nI feel so alive.",
    "lyrics_info": "Song lyrics with structure.",
    "instrumental_label": "Instrumental",
    "format_btn": "Format",
    "format_caption_btn": "Enhance Caption",
    "format_lyrics_btn": "Enhance Lyrics",
    "optional_params": "âš™ï¸ Optional Parameters",
    "optional_music_props": "ğŸµ Music Properties",
    "optional_gen_settings": "ğŸ“ Generation Settings",
    "advanced_dit_section": "ğŸ›ï¸ DiT Diffusion",
    "advanced_lm_section": "ğŸ¤– LM Generation",
    "advanced_output_section": "ğŸ”Š Audio Output & Post-processing",
    "advanced_automation_section": "âš¡ Automation & Batch",
    "vocal_language_label": "Vocal Language",
    "vocal_language_info": "'unknown' = instrumental / auto.",
    "bpm_label": "BPM",
    "bpm_info": "Leave empty for N/A.",
    "keyscale_label": "Key",
    "keyscale_placeholder": "Leave empty for N/A",
    "keyscale_info": "A-G, #/â™­, major/minor.",
    "timesig_label": "Time Signature",
    "timesig_info": "2/4, 3/4, 4/4.",
    "duration_label": "Audio Duration (seconds)",
    "duration_info": "Use -1 for random.",
    "batch_size_label": "Batch Size",
    "batch_size_info": "Number of audio to generate (max 8).",
    "advanced_settings": "âš™ï¸ Settings",
    "inference_steps_label": "DiT Inference Steps",
    "inference_steps_info": "Turbo: max 8, Base: max 200.",
    "guidance_scale_label": "DiT Guidance Scale (Only support for base model)",
    "guidance_scale_info": "Higher values follow text more closely.",
    "seed_label": "Seed",
    "seed_info": "Use comma-separated values for batches.",
    "random_seed_label": "Random Seed",
    "random_seed_info": "Enable to auto-generate seeds.",
    "audio_format_label": "Audio Format",
    "audio_format_info": "Audio format for saved files.",
    "use_adg_label": "Use ADG",
    "use_adg_info": "Enable Angle Domain Guidance.",
    "shift_label": "Shift",
    "shift_info": "Timestep shift factor for base models (range 1.0~5.0, default 3.0). Not effective for turbo models.",
    "infer_method_label": "Inference Method",
    "infer_method_info": "Diffusion inference method. ODE (Euler) is faster, SDE (stochastic) may produce different results.",
    "custom_timesteps_label": "Custom Timesteps",
    "custom_timesteps_info": "Comma-separated values from 1.0 to 0.0 (e.g., '0.97,0.76,0.615,0.5,0.395,0.28,0.18,0.085,0'). Overrides inference steps and shift.",
    "cfg_interval_start": "CFG Interval Start",
    "cfg_interval_end": "CFG Interval End",
    "lm_params_title": "ğŸ¤– LM Generation Parameters",
    "lm_temperature_label": "LM Temperature",
    "lm_temperature_info": "5Hz LM temperature (higher = more random).",
    "lm_cfg_scale_label": "LM CFG Scale",
    "lm_cfg_scale_info": "5Hz LM CFG (1.0 = no CFG).",
    "lm_top_k_label": "LM Top-K",
    "lm_top_k_info": "Top-K (0 = disabled).",
    "lm_top_p_label": "LM Top-P",
    "lm_top_p_info": "Top-P (1.0 = disabled).",
    "lm_negative_prompt_label": "LM Negative Prompt",
    "lm_negative_prompt_placeholder": "Enter negative prompt for CFG (default: NO USER INPUT)",
    "lm_negative_prompt_info": "Negative prompt (use when LM CFG Scale > 1.0).",
    "advanced_dit_params": "Advanced DiT Parameters",
    "cot_metas_label": "CoT Metas",
    "cot_metas_info": "Use LM to generate CoT metadata (uncheck to skip LM CoT generation).",
    "cot_language_label": "CoT Language",
    "cot_language_info": "Generate language in CoT (chain-of-thought).",
    "constrained_debug_label": "Constrained Decoding Debug",
    "constrained_debug_info": "Enable debug logging for constrained decoding (check to see detailed logs).",
    "auto_score_label": "Auto Score",
    "auto_score_info": "Automatically calculate quality scores for all generated audios.",
    "auto_lrc_label": "Auto LRC",
    "auto_lrc_info": "Automatically generate LRC lyrics timestamps for all generated audios.",
    "lm_batch_chunk_label": "LM Batch Chunk Size",
    "lm_batch_chunk_info": "Max items per LM batch chunk (default: 8, limited by GPU memory).",
    "codes_strength_label": "LM Codes Strength",
    "codes_strength_info": "Control how many denoising steps use LM-generated codes.",
    "cover_strength_label": "Audio Cover Strength",
    "cover_strength_info": "Control how many denoising steps use cover mode.",
    "remix_strength_label": "Remix Strength",
    "remix_strength_info": "Control how much the remix deviates from the source audio (lower = closer to original).",
    "cover_noise_strength_label": "Cover Strength",
    "cover_noise_strength_info": "Controls melody retention in Remix mode. Recommended: use the SFT model with a value of 0.1â€“0.25. A small increase restores the melody, but style transfer may require additional prompt tuning. (0 = pure noise/no cover, 1 = closest to original audio).",
    "score_sensitivity_label": "Quality Score Sensitivity",
    "score_sensitivity_info": "Lower = more sensitive (default: 1.0). Adjusts how PMI maps to [0,1].",
    "think_label": "Think",
    "parallel_thinking_label": "ParallelThinking",
    "parallel_thinking_info": "Process batch samples in parallel for faster generation.",
    "generate_btn": "ğŸµ Generate Music",
    "autogen_label": "AutoGen",
    "caption_rewrite_label": "CaptionRewrite",
    "caption_rewrite_info": "Use LM to rewrite caption before generation."
  },
  "results": {
    "title": "ğŸµ Results",
    "generated_music": "ğŸµ Generated Music (Sample {n})",
    "send_to_remix_btn": "ğŸ”— Send To Remix",
    "send_to_repaint_btn": "ğŸ”— Send To Repaint",
    "save_btn": "ğŸ’¾ Save",
    "score_btn": "ğŸ“Š Get Score",
    "lrc_btn": "ğŸµ Get LRC",
    "save_lrc_btn": "ğŸ’¾ Save LRC",
    "convert_to_codes_btn": "ğŸ”„ Convert To Codes",
    "quality_score_label": "Quality Score (Sample {n})",
    "quality_score_placeholder": "Click 'Score' to calculate perplexity-based quality score",
    "codes_label": "LM Codes (Sample {n})",
    "lrc_label": "Lyrics Timestamps (Sample {n})",
    "lrc_placeholder": "Click 'LRC' to generate timestamps",
    "details_accordion": "ğŸ“Š Score & LRC & LM Codes",
    "generation_status": "Generation Status",
    "current_batch": "Current Batch",
    "batch_indicator": "Batch {current} / {total}",
    "next_batch_status": "Next Batch Status",
    "prev_btn": "â—€ Previous",
    "next_btn": "Next â–¶",
    "restore_params_btn": "â†™ï¸ Apply These Settings to UI (Restore Batch Parameters)",
    "batch_results_title": "ğŸ“ Batch Results & Generation Details",
    "all_files_label": "ğŸ“ All Generated Files (Download)",
    "generation_details": "Generation Details"
  },
  "messages": {
    "no_audio_to_save": "âŒ No audio to save",
    "save_success": "âœ… Saved audio and metadata to {filename}",
    "save_failed": "âŒ Failed to save: {error}",
    "no_file_selected": "âš ï¸ No file selected",
    "params_loaded": "âœ… Parameters loaded from {filename}",
    "invalid_json": "âŒ Invalid JSON file: {error}",
    "load_error": "âŒ Error loading file: {error}",
    "example_loaded": "ğŸ“ Loaded example from {filename}",
    "example_failed": "Failed to parse JSON file {filename}: {error}",
    "example_error": "Error loading example: {error}",
    "lm_generated": "ğŸ¤– Generated example using LM",
    "lm_fallback": "Failed to generate example using LM, falling back to examples directory",
    "lm_not_initialized": "âŒ 5Hz LM not initialized. Please initialize it first.",
    "think_requires_lm": "âš ï¸ 'Think' requires 5Hz LM to be initialized. Think has been disabled â€” generation will proceed without LM thinking.",
    "autogen_enabled": "ğŸ”„ AutoGen enabled - next batch will generate after this",
    "batch_ready": "âœ… Batch {n} ready! Click 'Next' to view.",
    "batch_generating": "ğŸ”„ Starting background generation for Batch {n}.",
    "batch_failed": "âŒ Background generation failed: {error}",
    "viewing_batch": "âœ… Viewing Batch {n}",
    "at_first_batch": "Already at first batch",
    "at_last_batch": "No next batch available",
    "batch_not_found": "Batch {n} not found in queue",
    "no_batch_data": "No batch data found to restore.",
    "params_restored": "âœ… UI Parameters restored from Batch {n}",
    "scoring_failed": "âŒ Error: Batch data not found",
    "no_codes": "âŒ No audio codes available. Please generate music first.",
    "score_failed": "âŒ Scoring failed: {error}",
    "score_error": "âŒ Error calculating score: {error}",
    "lrc_no_batch_data": "âŒ No batch data found. Please generate music first.",
    "lrc_no_extra_outputs": "âŒ No extra outputs found. Condition tensors not available.",
    "lrc_missing_tensors": "âŒ Missing required tensors for LRC generation.",
    "lrc_sample_not_exist": "âŒ Sample does not exist in current batch.",
    "lrc_empty_result": "âš ï¸ LRC generation produced empty result.",
    "empty_query": "âš ï¸ Please enter a music description.",
    "sample_creation_failed": "âŒ Failed to create sample. Please try again.",
    "sample_created": "âœ… Sample created! Review the caption and lyrics, then click Generate Music.",
    "simple_examples_not_found": "âš ï¸ Simple mode examples directory not found.",
    "simple_examples_empty": "âš ï¸ No example files found in simple mode examples.",
    "simple_example_loaded": "ğŸ² Loaded random example from {filename}",
    "format_success": "âœ… Caption and lyrics formatted successfully",
    "format_failed": "âŒ Format failed: {error}",
    "skipping_metas_cot": "âš¡ Skipping Phase 1 metas COT (sample already formatted)",
    "invalid_timesteps_format": "âš ï¸ Invalid timesteps format. Using default schedule.",
    "timesteps_out_of_range": "âš ï¸ Timesteps must be in range [0, 1]. Using default schedule.",
    "timesteps_count_mismatch": "âš ï¸ Timesteps count ({actual}) differs from inference_steps ({expected}). Using timesteps count."
  },
  "training": {
    "tab_title": "ğŸ“ LoRA Training",
    "tab_dataset_builder": "ğŸ“ Dataset Builder",
    "tab_train_lora": "ğŸš€ Train LoRA",
    "quick_start_title": "ğŸš€ Quick Start",
    "load_dataset_label": "Dataset JSON Path",
    "load_dataset_info": "Load a previously saved dataset.",
    "load_btn": "ğŸ“‚ Load",
    "load_status": "Load Status",
    "scan_label": "Audio Directory Path",
    "scan_info": "Scan for audio files (wav, mp3, flac, ogg, opus).",
    "scan_btn": "ğŸ” Scan",
    "scan_status": "Scan Status",
    "found_audio_files": "Found Audio Files",
    "dataset_name": "Dataset Name",
    "dataset_name_placeholder": "Enter dataset name",
    "dataset_settings_header": "Dataset Settings",
    "tag_prepend": "Prepend (Tag, Caption)",
    "tag_append": "Append (Caption, Tag)",
    "tag_replace": "Replace Caption",
    "step2_title": "Step 2: AI Auto-Labeling",
    "step2_instruction": "Click the button below to use AI to automatically generate metadata for all audio files:\n- **Caption**: Music style, genre, mood description\n- **BPM**: Beats per minute\n- **Key**: Music key (e.g. C Major, Am)\n- **Time Signature**: 4/4, 3/4 etc.",
    "step3_title": "Step 3: Preview & Edit",
    "step4_title": "Step 4: Save Dataset",
    "step5_title": "Step 5: Preprocess to Tensors",
    "step5_intro": "**Preprocessing converts your dataset into pre-computed tensors for fast training.**\n\nYou can:\n- Use the dataset from steps 1-4 above, **OR**\n- Load an existing dataset JSON file (if you have one saved)",
    "step5_details": "This step will:\n- Encode audio to VAE latents\n- Encode captions and lyrics to text embeddings\n- Run condition encoders\n- Save all tensors to `.pt` files\n\nâš ï¸ **This requires loading models and may take a few minutes.**",
    "train_tensor_selection_desc": "Select the directory containing preprocessed tensor files (`.pt` files).\nThese are created using the 'Preprocess' button in the 'Dataset Builder' tab.",
    "all_instrumental": "All Instrumental",
    "all_instrumental_info": "Check if all tracks are instrumental (no vocals).",
    "custom_tag": "Custom Trigger Tag",
    "custom_tag_info": "Unique tag to activate this LoRA style.",
    "tag_position": "Tag Position",
    "tag_position_info": "Where to place the custom tag in the caption.",
    "genre_ratio": "Genre Ratio (%)",
    "genre_ratio_info": "0%=All Caption, 100%=All Genre. Single sample override takes precedence.",
    "skip_metas": "Skip BPM/Key/TimeSig",
    "skip_metas_info": "Skip BPM/Key/TimeSig generation. Captions and genres are still generated by LM.",
    "only_unlabeled": "Only Unlabeled",
    "only_unlabeled_info": "Only label samples with no caption (for continuing failed labeling).",
    "auto_label_btn": "ğŸ·ï¸ Auto-Label All",
    "label_progress": "Labeling Progress",
    "select_sample": "Select Sample #",
    "select_sample_info": "Select sample to preview and edit.",
    "audio_preview": "Audio Preview",
    "filename": "Filename",
    "caption": "Caption",
    "genre": "Genre",
    "prompt_override_label": "Prompt Override (This Sample)",
    "prompt_override_info": "Override global ratio for this sample.",
    "lyrics_editable_label": "Lyrics (Editable for Training)",
    "raw_lyrics_label": "Raw Lyrics (from .txt file)",
    "no_lyrics_placeholder": "(No .txt lyrics file)",
    "bpm": "BPM",
    "key_label": "Key",
    "key_placeholder": "C Major",
    "time_sig": "Time Sig",
    "duration_s": "Duration (s)",
    "language": "Language",
    "instrumental": "Instrumental",
    "save_changes_btn": "ğŸ’¾ Save Changes",
    "edit_status": "Edit Status",
    "save_path": "Save Path",
    "save_path_info": "Path to save dataset JSON.",
    "save_dataset_btn": "ğŸ’¾ Save Dataset",
    "save_status": "Save Status",
    "load_existing_label": "Load Existing Dataset",
    "load_existing_info": "Path to previously saved dataset JSON file.",
    "load_dataset_btn": "ğŸ“‚ Load Dataset",
    "tensor_output_dir": "Tensor Output Directory",
    "tensor_output_info": "Directory to save preprocessed tensor files.",
    "preprocess_btn": "âš¡ Preprocess",
    "preprocess_progress": "Preprocessing Progress",
    "preprocessed_tensors_dir": "Preprocessed Tensors Directory",
    "preprocessed_tensors_info": "Directory containing preprocessed .pt tensor files.",
    "dataset_info": "Dataset Info.",
    "lora_rank": "LoRA Rank (r)",
    "lora_rank_info": "Higher capacity but more VRAM.",
    "lora_alpha": "LoRA Alpha",
    "lora_alpha_info": "Scaling factor (usually 2x Rank).",
    "lora_dropout": "LoRA Dropout",
    "learning_rate": "Learning Rate",
    "learning_rate_info": "Start with 3e-4, adjust as needed.",
    "max_epochs": "Max Epochs",
    "batch_size": "Batch Size",
    "batch_size_info": "Increase if VRAM allows.",
    "gradient_accumulation": "Gradient Accumulation",
    "gradient_accumulation_info": "Effective Batch Size = batch_size * accum_steps.",
    "save_every_n_epochs": "Save Every N Epochs",
    "shift": "Shift",
    "shift_info": "Timestep shift for Turbo models.",
    "seed": "Seed",
    "output_dir": "Output Directory",
    "output_dir_info": "Directory to save trained LoRA weights.",
    "start_training_btn": "ğŸš€ Start Training",
    "stop_training_btn": "â¹ï¸ Stop Training",
    "training_progress": "Training Progress",
    "training_log": "Training Log",
    "training_loss_title": "Training Loss",
    "step": "Step",
    "loss": "Loss",
    "export_header": "Export LoRA",
    "export_path": "Export Path",
    "export_lora_btn": "ğŸ“¦ Export LoRA",
    "export_status": "Export Status"
  },
  "gen": {
    "enable_normalization": "Enable Normalization",
    "enable_normalization_info": "Normalize audio volume to target peak level to prevent clipping or ensure consistent loudness.",
    "normalization_db": "Target Peak (dB)",
    "normalization_db_info": "Target peak level in decibels. -1.0 dB is standard safe peak. -0.1 dB is max.",
    "latent_shift": "Latent Shift",
    "latent_shift_info": "Shift applied to DiT latents before VAE decode. Default 0 (no shift). Negative values (e.g. -0.04) can reduce clipping.",
    "latent_rescale": "Latent Rescale",
    "latent_rescale_info": "Rescale factor for DiT latents before VAE decode. Default 1.0 (no rescale). Values < 1.0 (e.g. 0.91) can reduce clipping."
  }
}