<h1 align="center">ACE-Step 1.5</h1>
<h1 align="center">Pushing the Boundaries of Open-Source Music Generation</h1>
<p align="center">
    <a href="https://ace-step.github.io/ace-step-v1.5.github.io/">Project</a> |
    <a href="https://huggingface.co/ACE-Step/Ace-Step1.5">Hugging Face</a> |
    <a href="https://modelscope.cn/models/ACE-Step/Ace-Step1.5">ModelScope</a> |
    <a href="https://huggingface.co/spaces/ACE-Step/Ace-Step-v1.5">Space Demo</a> |
    <a href="https://discord.gg/PeWDxrkdj7">Discord</a> |
    <a href="https://arxiv.org/abs/2602.00744">Technical Report</a>
</p>

<p align="center">
    <img src="./assets/orgnization_logos.png" width="100%" alt="StepFun Logo">
</p>

## Table of Contents

- [âœ¨ Features](#-features)
- [âš¡ Quick Start](#-quick-start)
- [ğŸš€ Launch Scripts](#-launch-scripts)
- [ğŸ“š Documentation](#-documentation)
- [ğŸ“– Tutorial](#-tutorial)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ¦ Model Zoo](#-model-zoo)
- [ğŸ”¬ Benchmark](#-benchmark)

## ğŸ“ Abstract
ğŸš€ We present ACE-Step v1.5, a highly efficient open-source music foundation model that brings commercial-grade generation to consumer hardware. On commonly used evaluation metrics, ACE-Step v1.5 achieves quality beyond most commercial music models while remaining extremely fastâ€”under 2 seconds per full song on an A100 and under 10 seconds on an RTX 3090. The model runs locally with less than 4GB of VRAM, and supports lightweight personalization: users can train a LoRA from just a few songs to capture their own style.

ğŸŒ‰ At its core lies a novel hybrid architecture where the Language Model (LM) functions as an omni-capable planner: it transforms simple user queries into comprehensive song blueprintsâ€”scaling from short loops to 10-minute compositionsâ€”while synthesizing metadata, lyrics, and captions via Chain-of-Thought to guide the Diffusion Transformer (DiT). âš¡ Uniquely, this alignment is achieved through intrinsic reinforcement learning relying solely on the model's internal mechanisms, thereby eliminating the biases inherent in external reward models or human preferences. ğŸšï¸

ğŸ”® Beyond standard synthesis, ACE-Step v1.5 unifies precise stylistic control with versatile editing capabilitiesâ€”such as cover generation, repainting, and vocal-to-BGM conversionâ€”while maintaining strict adherence to prompts across 50+ languages. This paves the way for powerful tools that seamlessly integrate into the creative workflows of music artists, producers, and content creators. ğŸ¸


## âœ¨ Features

<p align="center">
    <img src="./assets/application_map.png" width="100%" alt="ACE-Step Framework">
</p>

### âš¡ Performance
- âœ… **Ultra-Fast Generation** â€” Under 2s per full song on A100, under 10s on RTX 3090 (0.5s to 10s on A100 depending on think mode & diffusion steps)
- âœ… **Flexible Duration** â€” Supports 10 seconds to 10 minutes (600s) audio generation
- âœ… **Batch Generation** â€” Generate up to 8 songs simultaneously

### ğŸµ Generation Quality
- âœ… **Commercial-Grade Output** â€” Quality beyond most commercial music models (between Suno v4.5 and Suno v5)
- âœ… **Rich Style Support** â€” 1000+ instruments and styles with fine-grained timbre description
- âœ… **Multi-Language Lyrics** â€” Supports 50+ languages with lyrics prompt for structure & style control

### ğŸ›ï¸ Versatility & Control

| Feature | Description |
|---------|-------------|
| âœ… Reference Audio Input | Use reference audio to guide generation style |
| âœ… Cover Generation | Create covers from existing audio |
| âœ… Repaint & Edit | Selective local audio editing and regeneration |
| âœ… Track Separation | Separate audio into individual stems |
| âœ… Multi-Track Generation | Add layers like Suno Studio's "Add Layer" feature |
| âœ… Vocal2BGM | Auto-generate accompaniment for vocal tracks |
| âœ… Metadata Control | Control duration, BPM, key/scale, time signature |
| âœ… Simple Mode | Generate full songs from simple descriptions |
| âœ… Query Rewriting | Auto LM expansion of tags and lyrics |
| âœ… Audio Understanding | Extract BPM, key/scale, time signature & caption from audio |
| âœ… LRC Generation | Auto-generate lyric timestamps for generated music |
| âœ… LoRA Training | One-click annotation & training in Gradio. 8 songs, 1 hour on 3090 (12GB VRAM) |
| âœ… Quality Scoring | Automatic quality assessment for generated audio |

## Staying ahead
-----------------
Star ACE-Step on GitHub and be instantly notified of new releases
![](assets/star.gif)

## âš¡ Quick Start

> **Requirements:** Python 3.11-3.12, CUDA GPU recommended (also supports MPS / ROCm / Intel XPU / CPU)
> 
> **Note:** ROCm on Windows requires Python 3.12 (AMD officially provides Python 3.12 wheels only)

```bash
# 1. Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh          # macOS / Linux
# powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"  # Windows

# 2. Clone & install
git clone https://github.com/ACE-Step/ACE-Step-1.5.git
cd ACE-Step-1.5
uv sync

# 3. Launch Gradio UI (models auto-download on first run)
uv run acestep

# Or launch REST API server
uv run acestep-api
```

Open http://localhost:7860 (Gradio) or http://localhost:8001 (API).

> ğŸ“¦ **Windows users:** A [portable package](https://files.acemusic.ai/acemusic/win/ACE-Step-1.5.7z) with pre-installed dependencies is available. See [Installation Guide](./docs/en/INSTALL.md#-windows-portable-package).

> ğŸ“– **Full installation guide** (AMD/ROCm, Intel GPU, CPU, environment variables, command-line options): [English](./docs/en/INSTALL.md) | [ä¸­æ–‡](./docs/zh/INSTALL.md) | [æ—¥æœ¬èª](./docs/ja/INSTALL.md)

### ğŸ’¡ Which Model Should I Choose?

| Your GPU VRAM | Recommended LM Model | Backend | Notes |
|---------------|---------------------|---------|-------|
| **â‰¤6GB** | None (DiT only) | â€” | LM disabled by default; INT8 quantization + full CPU offload |
| **6-8GB** | `acestep-5Hz-lm-0.6B` | `pt` | Lightweight LM with PyTorch backend |
| **8-16GB** | `acestep-5Hz-lm-0.6B` / `1.7B` | `vllm` | 0.6B for 8-12GB, 1.7B for 12-16GB |
| **16-24GB** | `acestep-5Hz-lm-1.7B` | `vllm` | 4B available on 20GB+; no offload needed on 20GB+ |
| **â‰¥24GB** | `acestep-5Hz-lm-4B` | `vllm` | Best quality, all models fit without offload |

The UI automatically selects the best configuration for your GPU. All settings (LM model, backend, offloading, quantization) are tier-aware and pre-configured.

> ğŸ“– GPU compatibility details: [English](./docs/en/GPU_COMPATIBILITY.md) | [ä¸­æ–‡](./docs/zh/GPU_COMPATIBILITY.md) | [æ—¥æœ¬èª](./docs/ja/GPU_COMPATIBILITY.md) | [í•œêµ­ì–´](./docs/ko/GPU_COMPATIBILITY.md)

## ğŸš€ Launch Scripts

Ready-to-use launch scripts for all platforms with auto environment detection, update checking, and dependency installation.

| Platform | Scripts | Backend |
|----------|---------|---------|
| **Windows** | `start_gradio_ui.bat`, `start_api_server.bat` | CUDA |
| **Windows (ROCm)** | `start_gradio_ui_rocm.bat`, `start_api_server_rocm.bat` | AMD ROCm |
| **Linux** | `start_gradio_ui.sh`, `start_api_server.sh` | CUDA |
| **macOS** | `start_gradio_ui_macos.sh`, `start_api_server_macos.sh` | MLX (Apple Silicon) |

```bash
# Windows
start_gradio_ui.bat

# Linux
chmod +x start_gradio_ui.sh && ./start_gradio_ui.sh

# macOS (Apple Silicon)
chmod +x start_gradio_ui_macos.sh && ./start_gradio_ui_macos.sh
```

### âš™ï¸ Customizing Launch Settings

**Recommended:** Create a `.env` file to customize models, ports, and other settings. Your `.env` configuration will survive repository updates.

```bash
# Copy the example file
cp .env.example .env

# Edit with your preferred settings
# Examples in .env:
ACESTEP_CONFIG_PATH=acestep-v15-turbo
ACESTEP_LM_MODEL_PATH=acestep-5Hz-lm-1.7B
PORT=7860
LANGUAGE=en
```

> ğŸ“– **Script configuration & customization:** [English](./docs/en/INSTALL.md#-launch-scripts) | [ä¸­æ–‡](./docs/zh/INSTALL.md#-å¯åŠ¨è„šæœ¬) | [æ—¥æœ¬èª](./docs/ja/INSTALL.md#-èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ)

## ğŸ“š Documentation

### Usage Guides

| Method | Description | Documentation |
|--------|-------------|---------------|
| ğŸ–¥ï¸ **Gradio Web UI** | Interactive web interface for music generation | [Guide](./docs/en/GRADIO_GUIDE.md) |
| ğŸšï¸ **Studio UI** | Optional HTML frontend (DAW-like) | [Guide](./docs/en/studio.md) |
| ğŸ **Python API** | Programmatic access for integration | [Guide](./docs/en/INFERENCE.md) |
| ğŸŒ **REST API** | HTTP-based async API for services | [Guide](./docs/en/API.md) |
| âŒ¨ï¸ **CLI** | Interactive wizard and configuration | [Guide](./docs/en/CLI.md) |

### Setup & Configuration

| Topic | Documentation |
|-------|---------------|
| ğŸ“¦ Installation (all platforms) | [English](./docs/en/INSTALL.md) \| [ä¸­æ–‡](./docs/zh/INSTALL.md) \| [æ—¥æœ¬èª](./docs/ja/INSTALL.md) |
| ğŸ® GPU Compatibility | [English](./docs/en/GPU_COMPATIBILITY.md) \| [ä¸­æ–‡](./docs/zh/GPU_COMPATIBILITY.md) \| [æ—¥æœ¬èª](./docs/ja/GPU_COMPATIBILITY.md) |
| ğŸ”§ GPU Troubleshooting | [English](./docs/en/GPU_TROUBLESHOOTING.md) |
| ğŸ”¬ Benchmark & Profiling | [English](./docs/en/BENCHMARK.md) \| [ä¸­æ–‡](./docs/zh/BENCHMARK.md) |

### Multi-Language Docs

| Language | API | Gradio | Inference | Tutorial | LoRA Training | Install | Benchmark |
|----------|-----|--------|-----------|----------|---------------|---------|-----------|
| ğŸ‡ºğŸ‡¸ English | [Link](./docs/en/API.md) | [Link](./docs/en/GRADIO_GUIDE.md) | [Link](./docs/en/INFERENCE.md) | [Link](./docs/en/Tutorial.md) | [Link](./docs/en/LoRA_Training_Tutorial.md) | [Link](./docs/en/INSTALL.md) | [Link](./docs/en/BENCHMARK.md) |
| ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | [Link](./docs/zh/API.md) | [Link](./docs/zh/GRADIO_GUIDE.md) | [Link](./docs/zh/INFERENCE.md) | [Link](./docs/zh/Tutorial.md) | [Link](./docs/zh/LoRA_Training_Tutorial.md) | [Link](./docs/zh/INSTALL.md) | [Link](./docs/zh/BENCHMARK.md) |
| ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª | [Link](./docs/ja/API.md) | [Link](./docs/ja/GRADIO_GUIDE.md) | [Link](./docs/ja/INFERENCE.md) | [Link](./docs/ja/Tutorial.md) | [Link](./docs/ja/LoRA_Training_Tutorial.md) | [Link](./docs/ja/INSTALL.md) | â€” |
| ğŸ‡°ğŸ‡· í•œêµ­ì–´ | [Link](./docs/ko/API.md) | [Link](./docs/ko/GRADIO_GUIDE.md) | [Link](./docs/ko/INFERENCE.md) | [Link](./docs/ko/Tutorial.md) | [Link](./docs/ko/LoRA_Training_Tutorial.md) | â€” | â€” |

## ğŸ“– Tutorial

**ğŸ¯ Must Read:** Comprehensive guide to ACE-Step 1.5's design philosophy and usage methods.

| Language | Link |
|----------|------|
| ğŸ‡ºğŸ‡¸ English | [English Tutorial](./docs/en/Tutorial.md) |
| ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | [ä¸­æ–‡æ•™ç¨‹](./docs/zh/Tutorial.md) |
| ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª | [æ—¥æœ¬èªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](./docs/ja/Tutorial.md) |

This tutorial covers: mental models and design philosophy, model architecture and selection, input control (text and audio), inference hyperparameters, random factors and optimization strategies.

## ğŸ”¨ Train

ğŸ“– **LoRA Training Tutorial** â€” step-by-step guide covering data preparation, annotation, preprocessing, and training:

| Language | Link |
|----------|------|
| ğŸ‡ºğŸ‡¸ English | [LoRA Training Tutorial](./docs/en/LoRA_Training_Tutorial.md) |
| ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | [LoRA è®­ç»ƒæ•™ç¨‹](./docs/zh/LoRA_Training_Tutorial.md) |
| ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª | [LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](./docs/ja/LoRA_Training_Tutorial.md) |
| ğŸ‡°ğŸ‡· í•œêµ­ì–´ | [LoRA í•™ìŠµ íŠœí† ë¦¬ì–¼](./docs/ko/LoRA_Training_Tutorial.md) |

See also the **LoRA Training** tab in Gradio UI for one-click training, or [Gradio Guide - LoRA Training](./docs/en/GRADIO_GUIDE.md#lora-training) for UI reference.

ğŸ”§ **Advanced Training with [Side-Step](https://github.com/koda-dernet/Side-Step)** â€” CLI-based training toolkit with corrected timestep sampling, LoKR adapters, VRAM optimization, gradient sensitivity analysis, and more. See the [Side-Step documentation](./docs/sidestep/Getting%20Started.md).

## ğŸ—ï¸ Architecture

<p align="center">
    <img src="./assets/ACE-Step_framework.png" width="100%" alt="ACE-Step Framework">
</p>

## ğŸ¦ Model Zoo

<p align="center">
    <img src="./assets/model_zoo.png" width="100%" alt="Model Zoo">
</p>

### DiT Models

| DiT Model | Pre-Training | SFT | RL | CFG | Step | Refer audio | Text2Music | Cover | Repaint | Extract | Lego | Complete | Quality | Diversity | Fine-Tunability | Hugging Face |
|-----------|:------------:|:---:|:--:|:---:|:----:|:-----------:|:----------:|:-----:|:-------:|:-------:|:----:|:--------:|:-------:|:---------:|:---------------:|--------------|
| `acestep-v15-base` | âœ… | âŒ | âŒ | âœ… | 50 | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | Medium | High | Easy | [Link](https://huggingface.co/ACE-Step/acestep-v15-base) |
| `acestep-v15-sft` | âœ… | âœ… | âŒ | âœ… | 50 | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | High | Medium | Easy | [Link](https://huggingface.co/ACE-Step/acestep-v15-sft) |
| `acestep-v15-turbo` | âœ… | âœ… | âŒ | âŒ | 8 | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | Very High | Medium | Medium | [Link](https://huggingface.co/ACE-Step/Ace-Step1.5) |
| `acestep-v15-turbo-rl` | âœ… | âœ… | âœ… | âŒ | 8 | âœ… | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | Very High | Medium | Medium | To be released |

### LM Models

| LM Model | Pretrain from | Pre-Training | SFT | RL | CoT metas | Query rewrite | Audio Understanding | Composition Capability | Copy Melody | Hugging Face |
|----------|---------------|:------------:|:---:|:--:|:---------:|:-------------:|:-------------------:|:----------------------:|:-----------:|--------------|
| `acestep-5Hz-lm-0.6B` | Qwen3-0.6B | âœ… | âœ… | âœ… | âœ… | âœ… | Medium | Medium | Weak | âœ… |
| `acestep-5Hz-lm-1.7B` | Qwen3-1.7B | âœ… | âœ… | âœ… | âœ… | âœ… | Medium | Medium | Medium | âœ… |
| `acestep-5Hz-lm-4B` | Qwen3-4B | âœ… | âœ… | âœ… | âœ… | âœ… | Strong | Strong | Strong | âœ… |

## ğŸ”¬ Benchmark

ACE-Step 1.5 includes `profile_inference.py`, a profiling & benchmarking tool that measures LLM, DiT, and VAE timing across devices and configurations.

```bash
python profile_inference.py                        # Single-run profile
python profile_inference.py --mode benchmark       # Configuration matrix
```

> ğŸ“– **Full guide** (all modes, CLI options, output interpretation): [English](./docs/en/BENCHMARK.md) | [ä¸­æ–‡](./docs/zh/BENCHMARK.md)

## ğŸ“œ License & Disclaimer

This project is licensed under [MIT](./LICENSE)

ACE-Step enables original music generation across diverse genres, with applications in creative production, education, and entertainment. While designed to support positive and artistic use cases, we acknowledge potential risks such as unintentional copyright infringement due to stylistic similarity, inappropriate blending of cultural elements, and misuse for generating harmful content. To ensure responsible use, we encourage users to verify the originality of generated works, clearly disclose AI involvement, and obtain appropriate permissions when adapting protected styles or materials. By using ACE-Step, you agree to uphold these principles and respect artistic integrity, cultural diversity, and legal compliance. The authors are not responsible for any misuse of the model, including but not limited to copyright violations, cultural insensitivity, or the generation of harmful content.

ğŸ”” Important Notice  
The only official website for the ACE-Step project is our GitHub Pages site.    
 We do not operate any other websites.  
ğŸš« Fake domains include but are not limited to:
ac\*\*p.com, a\*\*p.org, a\*\*\*c.org  
âš ï¸ Please be cautious. Do not visit, trust, or make payments on any of those sites.

## ğŸ™ Acknowledgements

This project is co-led by ACE Studio and StepFun.


## ğŸ“– Citation

If you find this project useful for your research, please consider citing:

```BibTeX
@misc{gong2026acestep,
	title={ACE-Step 1.5: Pushing the Boundaries of Open-Source Music Generation},
	author={Junmin Gong, Yulin Song, Wenxiao Zhao, Sen Wang, Shengyuan Xu, Jing Guo}, 
	howpublished={\url{https://github.com/ace-step/ACE-Step-1.5}},
	year={2026},
	note={GitHub repository}
}
```
